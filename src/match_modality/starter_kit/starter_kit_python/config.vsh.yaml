functionality:
  name: python_starter_kit
  namespace: match_modality_starter_kits
  
  # metadata for your method
  version: dev
  description: A description for your method.
  authors:
    - name: John Doe
      email: johndoe@youremailprovider.com
      roles: [ author, maintainer ]
      props: { github: johndoe, orcid: "0000-1111-2222-3333" }
      
  # parameters
  arguments:
    # required inputs
    - name: "--input_train_mod1"
      type: "file"
      example: "dataset_censored.h5ad"
      description: "The censored shuffled train mod1 profiles."
      required: true
    - name: "--input_train_mod2"
      type: "file"
      example: "dataset_censored.h5ad"
      description: "The censored shuffled train mod2 profiles."
      required: true
    - name: "--input_train_sol"
      type: "file"
      example: "dataset_solution.h5ad"
      description: "The pairing of train mod1&mod2 profiles."
      required: true
    - name: "--input_test_mod1"
      type: "file"
      example: "dataset_censored.h5ad"
      description: "The censored shuffled test mod1 profiles."
      required: true
    - name: "--input_test_mod2"
      type: "file"
      example: "dataset_censored.h5ad"
      description: "The censored shuffled test mod2 profiles."
      required: true
    # required outputs
    - name: "--output"
      type: "file"
      direction: "output"
      example: "output.h5ad"
      description: "The predicted pairing of test mod1&mod2 profiles."
      required: true
    # Method-specific parameters. Change these to expose parameters of your method to Nextflow (optional)
    - name: "--distance_method"
      type: "string"
      default: "minkowski"
      description: The distance metric to use. Possible values include `euclidean` and `minkowski`.
    - name: "--n_pcs"
      type: "integer"
      default: 4
      description: Number of components to use for dimensionality reduction.
    - name: "--n_neighbors"
      type: "integer"
      default: 5
      description: Number of neighbors to use.
      
  # files your script needs
  resources:
    - type: python_script
      path: script.py
  
  # resources for unit testing your component
  tests:
    - type: python_script
      path: test.py
    - path: sample_data

# target platforms
platforms:

  # By specifying 'docker' platform, viash will build a standalone
  # executable which uses docker in the back end to run your method.
  - type: docker
    # you need to specify a base image that contains at least bash and python
    image: dataintuitive/randpy:py3.8
    # You can specify additional dependencies with 'setup'. 
    # See https://viash.io/docs/reference_config/platform-docker/#setup-list
    # for more information on how to add more dependencies.
    setup:
      # - type: apt
      #   packages:
      #     - bash
      # - type: python
      #   packages:
      #     - scanpy
      - type: python
        packages:
          - scikit-learn
          - anndata
          - scanpy

  # By specifying a 'nextflow', viash will also build a viash module
  # which uses the docker container built above to also be able to 
  # run your method as part of a nextflow pipeline.
  - type: nextflow
    labels: [ lowmem, lowtime, lowcpu ]

  # used for saturn cloud
  - type: native