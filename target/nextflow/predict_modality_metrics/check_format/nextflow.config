  docker.enabled = true
  docker.runOptions = "-i -v ${baseDir}:${baseDir}"
  process.container = "dataintuitive/viash"
  params {
    check_format__input_prediction = "viash_no_value"
    check_format__input_solution = "viash_no_value"
    check_format__output = "viash_no_value"
    id = ""
    testScript = "test_metric.py"
    testResources = [ "../../unit_tests/test_metric.py", "../../../../resources_test", "metric_meta_check_format.tsv" ]
    check_format {
      name = "check_format"
      container = "predict_modality_metrics_check_format"
      containerTag = "1.0.0"
      containerRegistry = "openproblems"
      command = "check_format"
      tests {
        isDefined = true
        testScript = "test_metric.py"
        testResources = [ "../../unit_tests/test_metric.py", "../../../../resources_test", "metric_meta_check_format.tsv" ]
      }
      arguments {
        input_prediction {
          name = "input_prediction"
          otype = "--"
          required = true
          type = "file"
          direction = "Input"
          multiple = false
          multiple_sep = ":"
          value = "${params.check_format__input_prediction}"
          example = "prediction.h5ad"
          description = "Prediction by a method"
        }
        input_solution {
          name = "input_solution"
          otype = "--"
          required = true
          type = "file"
          direction = "Input"
          multiple = false
          multiple_sep = ":"
          value = "${params.check_format__input_solution}"
          example = "solution.h5ad"
          description = "Gold standard solution"
        }
        output {
          name = "output"
          otype = "--"
          required = true
          type = "file"
          direction = "Output"
          multiple = false
          multiple_sep = ":"
          value = "${params.check_format__output}"
          example = "output.h5ad"
          description = "Metric scores by comparing the prediction to the gold standard solution."
        }
      }
    }
  }