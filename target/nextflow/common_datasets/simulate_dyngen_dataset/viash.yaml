functionality:
  name: "simulate_dyngen_dataset"
  namespace: "common_datasets"
  version: "main_build"
  authors:
  - name: "Robrecht Cannoodt"
    email: "rcannood@gmail.com"
    roles:
    - "author"
    - "maintainer"
    props:
      github: "rcannood"
      orcid: "0000-0003-3641-729X"
  arguments:
  - type: "string"
    name: "--id"
    alternatives: []
    description: "The id of the output dataset id"
    example: "dyngen_dataset"
    required: true
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "file"
    name: "--output_rna"
    alternatives: []
    description: "Output h5ad RNA file."
    example: "output_rna.h5ad"
    must_exist: false
    required: true
    direction: "Output"
    multiple: false
    multiple_sep: ":"
  - type: "file"
    name: "--output_mod2"
    alternatives: []
    description: "Output h5ad modality2 file (ATAC or Antibody capture)."
    example: "output_mod2.h5ad"
    must_exist: false
    required: true
    direction: "Output"
    multiple: false
    multiple_sep: ":"
  - type: "file"
    name: "--plot"
    alternatives:
    - "-p"
    description: "A visualisation of the simulation."
    example: "plot.pdf"
    must_exist: false
    required: true
    direction: "Output"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--num_cells"
    alternatives: []
    description: "The number of cells to generate."
    default: 100
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--num_genes"
    alternatives: []
    description: "The number of genes to generate."
    default: 100
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--num_simulations"
    alternatives: []
    description: "The number of dyngen simulations to run."
    default: 32
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--census_interval"
    alternatives: []
    description: "A granularity parameter for the outputted simulation."
    default: 4.0
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--ssa_tau"
    alternatives: []
    description: "Step size of the GillespieSSA2 simulation. Default is 30/3600."
    default: 0.008333
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "boolean_true"
    name: "--store_chromatin"
    alternatives:
    - "-chromatin"
    description: "Whether or not to compute chromatin accessibility data."
    direction: "Input"
  - type: "boolean_true"
    name: "--store_protein"
    alternatives:
    - "-protein"
    description: "Whether or not to store protein count information."
    direction: "Input"
  - type: "integer"
    name: "--num_proteins"
    alternatives: []
    description: "The number of proteins to sample."
    default: 50
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--num_threads"
    alternatives: []
    description: "Parallellisation level."
    default: 1
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--seed"
    alternatives: []
    description: "Seed"
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  - type: "file"
    name: "--cache_dir"
    alternatives: []
    description: "A caching directory for files that dyngen downloads."
    must_exist: false
    required: false
    direction: "Input"
    multiple: false
    multiple_sep: ":"
  resources:
  - type: "bash_script"
    text: |
      #!/usr/bin/env bash
      
      ############################################
      #    simulate_dyngen_dataset main_build    #
      ############################################
      
      # This wrapper script is auto-generated by viash 0.5.3dev and is thus a
      # derivative work thereof. This software comes with ABSOLUTELY NO WARRANTY from
      # Data Intuitive.  The component may contain files which fall under a different
      # license. The authors of this component should specify the license in the
      # header of such files, or include a separate license file detailing the
      # licenses of all included files.
      #
      # Component authors:
      # * Robrecht Cannoodt <rcannood@gmail.com> (author, maintainer) {github: rcannood, orcid: 0000-0003-3641-729X}
      
      set -e
      
      if [ -z "$VIASH_TEMP" ]; then
        VIASH_TEMP=/tmp
      fi
      
      # define helper functions
      # ViashQuote: put quotes around non flag values
      # $1     : unquoted string
      # return : possibly quoted string
      # examples:
      #   ViashQuote --foo      # returns --foo
      #   ViashQuote bar        # returns 'bar'
      #   Viashquote --foo=bar  # returns --foo='bar'
      function ViashQuote {
        if [[ "$1" =~ ^-+[a-zA-Z0-9_\-]+=.+$ ]]; then
          echo "$1" | sed "s#=\(.*\)#='\1'#"
        elif [[ "$1" =~ ^-+[a-zA-Z0-9_\-]+$ ]]; then
          echo "$1"
        else
          echo "'$1'"
        fi
      }
      # ViashRemoveFlags: Remove leading flag
      # $1     : string with a possible leading flag
      # return : string without possible leading flag
      # examples:
      #   ViashRemoveFlags --foo=bar  # returns bar
      function ViashRemoveFlags {
        echo "$1" | sed 's/^--*[a-zA-Z0-9_\-]*=//'
      }
      # ViashSourceDir: return the path of a bash file, following symlinks
      # usage   : ViashSourceDir ${BASH_SOURCE[0]}
      # $1      : Should always be set to ${BASH_SOURCE[0]}
      # returns : The absolute path of the bash file
      function ViashSourceDir {
        SOURCE="$1"
        while [ -h "$SOURCE" ]; do
          DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd )"
          SOURCE="$(readlink "$SOURCE")"
          [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE"
        done
        cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd
      }
      VIASH_VERBOSITY=5
      
      # see https://en.wikipedia.org/wiki/Syslog#Severity_level
      
      # ViashLog: Log events depending on the verbosity level
      # usage: ViashLog 1 alert Oh no something went wrong!
      # $1: required verbosity level
      # $2: display tag
      # $3+: messages to display
      # stdout: Your input, prepended by '[$2] '. 
      function ViashLog {
        local required_level="$1"
        local display_tag="$2"
        shift 2
        if [ $VIASH_VERBOSITY -ge $required_level ]; then
          echo "[$display_tag]" "$@"
        fi
      }
      
      # ViashEmergency: log events when the system is unstable
      # usage: ViashEmergency Oh no something went wrong.
      # stdout: Your input, prepended by '[emergency] '. 
      function ViashEmergency {
        ViashLog 0 emergency $@
      }
      
      # ViashAlert: log events when actions must be taken immediately (e.g. corrupted system database)
      # usage: ViashAlert Oh no something went wrong.
      # stdout: Your input, prepended by '[alert] '. 
      function ViashAlert {
        ViashLog 1 alert $@
      }
      
      # ViashCritical: log events when a critical condition occurs
      # usage: ViashCritical Oh no something went wrong.
      # stdout: Your input, prepended by '[critical] '. 
      function ViashCritical {
        ViashLog 2 critical $@
      }
      
      # ViashError: log events when an error condition occurs
      # usage: ViashError Oh no something went wrong.
      # stdout: Your input, prepended by '[error] '. 
      function ViashError {
        ViashLog 3 error $@
      }
      
      # ViashWarning: log potentially abnormal events
      # usage: ViashWarning Something may have gone wrong.
      # stdout: Your input, prepended by '[warning] '. 
      function ViashWarning {
        ViashLog 4 warning $@
      }
      
      # ViashNotice: log significant but normal events
      # usage: ViashNotice This just happened.
      # stdout: Your input, prepended by '[notice] '. 
      function ViashNotice {
        ViashLog 5 notice $@
      }
      
      # ViashInfo: log normal events
      # usage: ViashInfo This just happened.
      # stdout: Your input, prepended by '[info] '. 
      function ViashInfo {
        ViashLog 6 info $@
      }
      
      # ViashDebug: log all events, for debugging purposes
      # usage: ViashDebug This just happened.
      # stdout: Your input, prepended by '[debug] '. 
      function ViashDebug {
        ViashLog 7 debug $@
      }
      
      # find source folder of this component
      VIASH_RESOURCES_DIR=`ViashSourceDir ${BASH_SOURCE[0]}`
      
      # define meta fields
      VIASH_META_FUNCTIONALITY_NAME="simulate_dyngen_dataset"
      
      
      # ViashHelp: Display helpful explanation about this executable
      function ViashHelp {
        echo "simulate_dyngen_dataset main_build"
        echo "Generate a synthetic dataset using the standard dyngen simulation workflow."
        echo "For more advanced usage to get more control over the outputted dataset, use the"
        echo "R package. More documentation can be found at https://dyngen.dynverse.org."
        echo
        echo "Options:"
      
        echo "   --id"
        echo "        type: string, required parameter"
        echo "        example: dyngen_dataset"
        echo "        The id of the output dataset id"
        echo ""
      
      
        echo "   --output_rna"
        echo "        type: file, required parameter, output"
        echo "        example: output_rna.h5ad"
        echo "        Output h5ad RNA file."
        echo ""
      
      
        echo "   --output_mod2"
        echo "        type: file, required parameter, output"
        echo "        example: output_mod2.h5ad"
        echo "        Output h5ad modality2 file (ATAC or Antibody capture)."
        echo ""
      
      
        echo "   -p, --plot"
        echo "        type: file, required parameter, output"
        echo "        example: plot.pdf"
        echo "        A visualisation of the simulation."
        echo ""
      
      
        echo "   --num_cells"
        echo "        type: integer"
        echo "        default: 100"
        echo "        The number of cells to generate."
        echo ""
      
      
        echo "   --num_genes"
        echo "        type: integer"
        echo "        default: 100"
        echo "        The number of genes to generate."
        echo ""
      
      
        echo "   --num_simulations"
        echo "        type: integer"
        echo "        default: 32"
        echo "        The number of dyngen simulations to run."
        echo ""
      
      
        echo "   --census_interval"
        echo "        type: double"
        echo "        default: 4.0"
        echo "        A granularity parameter for the outputted simulation."
        echo ""
      
      
        echo "   --ssa_tau"
        echo "        type: double"
        echo "        default: 0.008333"
        echo "        Step size of the GillespieSSA2 simulation. Default is 30/3600."
        echo ""
      
      
        echo "   -chromatin, --store_chromatin"
        echo "        type: boolean_true"
        echo "        Whether or not to compute chromatin accessibility data."
        echo ""
      
      
        echo "   -protein, --store_protein"
        echo "        type: boolean_true"
        echo "        Whether or not to store protein count information."
        echo ""
      
      
        echo "   --num_proteins"
        echo "        type: integer"
        echo "        default: 50"
        echo "        The number of proteins to sample."
        echo ""
      
      
        echo "   --num_threads"
        echo "        type: integer"
        echo "        default: 1"
        echo "        Parallellisation level."
        echo ""
      
      
        echo "   --seed"
        echo "        type: integer"
        echo "        Seed"
        echo ""
      
      
        echo "   --cache_dir"
        echo "        type: file"
        echo "        A caching directory for files that dyngen downloads."
        echo ""
      
      }
      
      # initialise array
      VIASH_POSITIONAL_ARGS=''
      
      while [[ $# -gt 0 ]]; do
          case "$1" in
              -h|--help)
                  ViashHelp
                  exit
                  ;;
              -v|--verbose)
                  let "VIASH_VERBOSITY=VIASH_VERBOSITY+1"
                  shift 1
                  ;;
              -vv)
                  let "VIASH_VERBOSITY=VIASH_VERBOSITY+2"
                  shift 1
                  ;;
              --verbosity)
                  VIASH_VERBOSITY="$2"
                  shift 2
                  ;;
              --verbosity=*)
                  VIASH_VERBOSITY="$(ViashRemoveFlags "$1")"
                  shift 1
                  ;;
              --version)
                  echo "simulate_dyngen_dataset main_build"
                  exit
                  ;;
              --id)
                  VIASH_PAR_ID="$2"
                  shift 2
                  ;;
              --id=*)
                  VIASH_PAR_ID=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --output_rna)
                  VIASH_PAR_OUTPUT_RNA="$2"
                  shift 2
                  ;;
              --output_rna=*)
                  VIASH_PAR_OUTPUT_RNA=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --output_mod2)
                  VIASH_PAR_OUTPUT_MOD2="$2"
                  shift 2
                  ;;
              --output_mod2=*)
                  VIASH_PAR_OUTPUT_MOD2=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --plot)
                  VIASH_PAR_PLOT="$2"
                  shift 2
                  ;;
              --plot=*)
                  VIASH_PAR_PLOT=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              -p)
                  VIASH_PAR_PLOT="$2"
                  shift 2
                  ;;
              --num_cells)
                  VIASH_PAR_NUM_CELLS="$2"
                  shift 2
                  ;;
              --num_cells=*)
                  VIASH_PAR_NUM_CELLS=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --num_genes)
                  VIASH_PAR_NUM_GENES="$2"
                  shift 2
                  ;;
              --num_genes=*)
                  VIASH_PAR_NUM_GENES=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --num_simulations)
                  VIASH_PAR_NUM_SIMULATIONS="$2"
                  shift 2
                  ;;
              --num_simulations=*)
                  VIASH_PAR_NUM_SIMULATIONS=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --census_interval)
                  VIASH_PAR_CENSUS_INTERVAL="$2"
                  shift 2
                  ;;
              --census_interval=*)
                  VIASH_PAR_CENSUS_INTERVAL=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --ssa_tau)
                  VIASH_PAR_SSA_TAU="$2"
                  shift 2
                  ;;
              --ssa_tau=*)
                  VIASH_PAR_SSA_TAU=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --store_chromatin)
                  VIASH_PAR_STORE_CHROMATIN=true
                  shift 1
                  ;;
              -chromatin)
                  VIASH_PAR_STORE_CHROMATIN=true
                  shift 1
                  ;;
              --store_protein)
                  VIASH_PAR_STORE_PROTEIN=true
                  shift 1
                  ;;
              -protein)
                  VIASH_PAR_STORE_PROTEIN=true
                  shift 1
                  ;;
              --num_proteins)
                  VIASH_PAR_NUM_PROTEINS="$2"
                  shift 2
                  ;;
              --num_proteins=*)
                  VIASH_PAR_NUM_PROTEINS=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --num_threads)
                  VIASH_PAR_NUM_THREADS="$2"
                  shift 2
                  ;;
              --num_threads=*)
                  VIASH_PAR_NUM_THREADS=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --seed)
                  VIASH_PAR_SEED="$2"
                  shift 2
                  ;;
              --seed=*)
                  VIASH_PAR_SEED=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              --cache_dir)
                  VIASH_PAR_CACHE_DIR="$2"
                  shift 2
                  ;;
              --cache_dir=*)
                  VIASH_PAR_CACHE_DIR=$(ViashRemoveFlags "$1")
                  shift 1
                  ;;
              *)  # positional arg or unknown option
                  # since the positional args will be eval'd, can we always quote, instead of using ViashQuote
                  VIASH_POSITIONAL_ARGS="$VIASH_POSITIONAL_ARGS '$1'"
                  shift # past argument
                  ;;
          esac
      done
      
      # parse positional parameters
      eval set -- $VIASH_POSITIONAL_ARGS
      
      
      
      # check whether required parameters exist
      if [ -z "$VIASH_PAR_ID" ]; then
        ViashError '--id' is a required argument. Use "--help" to get more information on the parameters.
        exit 1
      fi
      if [ -z "$VIASH_PAR_OUTPUT_RNA" ]; then
        ViashError '--output_rna' is a required argument. Use "--help" to get more information on the parameters.
        exit 1
      fi
      if [ -z "$VIASH_PAR_OUTPUT_MOD2" ]; then
        ViashError '--output_mod2' is a required argument. Use "--help" to get more information on the parameters.
        exit 1
      fi
      if [ -z "$VIASH_PAR_PLOT" ]; then
        ViashError '--plot' is a required argument. Use "--help" to get more information on the parameters.
        exit 1
      fi
      if [ -z "$VIASH_PAR_NUM_CELLS" ]; then
        VIASH_PAR_NUM_CELLS="100"
      fi
      if [ -z "$VIASH_PAR_NUM_GENES" ]; then
        VIASH_PAR_NUM_GENES="100"
      fi
      if [ -z "$VIASH_PAR_NUM_SIMULATIONS" ]; then
        VIASH_PAR_NUM_SIMULATIONS="32"
      fi
      if [ -z "$VIASH_PAR_CENSUS_INTERVAL" ]; then
        VIASH_PAR_CENSUS_INTERVAL="4.0"
      fi
      if [ -z "$VIASH_PAR_SSA_TAU" ]; then
        VIASH_PAR_SSA_TAU="0.008333"
      fi
      if [ -z "$VIASH_PAR_STORE_CHROMATIN" ]; then
        VIASH_PAR_STORE_CHROMATIN="false"
      fi
      if [ -z "$VIASH_PAR_STORE_PROTEIN" ]; then
        VIASH_PAR_STORE_PROTEIN="false"
      fi
      if [ -z "$VIASH_PAR_NUM_PROTEINS" ]; then
        VIASH_PAR_NUM_PROTEINS="50"
      fi
      if [ -z "$VIASH_PAR_NUM_THREADS" ]; then
        VIASH_PAR_NUM_THREADS="1"
      fi
      
      
      cat << VIASHEOF | bash
      set -e
      tempscript=\$(mktemp "$VIASH_TEMP/viash-run-simulate_dyngen_dataset-XXXXXX")
      function clean_up {
        rm "\$tempscript"
      }
      trap clean_up EXIT
      cat > "\$tempscript" << 'VIASHMAIN'
      cat("Loading dependencies\\n")
      options(tidyverse.quiet = TRUE)
      library(tidyverse)
      library(dyngen, quietly = TRUE, warn.conflicts = FALSE)
      library(Matrix, quietly = TRUE, warn.conflicts = FALSE)
      requireNamespace("anndata", quietly = TRUE)
      
      ## VIASH START
      # The following code has been auto-generated by Viash.
      # get parameters from cli
      par <- list(
        "id" = $( if [ ! -z ${VIASH_PAR_ID+x} ]; then echo "'$VIASH_PAR_ID'"; else echo NULL; fi ),
        "output_rna" = $( if [ ! -z ${VIASH_PAR_OUTPUT_RNA+x} ]; then echo "'$VIASH_PAR_OUTPUT_RNA'"; else echo NULL; fi ),
        "output_mod2" = $( if [ ! -z ${VIASH_PAR_OUTPUT_MOD2+x} ]; then echo "'$VIASH_PAR_OUTPUT_MOD2'"; else echo NULL; fi ),
        "plot" = $( if [ ! -z ${VIASH_PAR_PLOT+x} ]; then echo "'$VIASH_PAR_PLOT'"; else echo NULL; fi ),
        "num_cells" = $( if [ ! -z ${VIASH_PAR_NUM_CELLS+x} ]; then echo "as.integer($VIASH_PAR_NUM_CELLS)"; else echo NULL; fi ),
        "num_genes" = $( if [ ! -z ${VIASH_PAR_NUM_GENES+x} ]; then echo "as.integer($VIASH_PAR_NUM_GENES)"; else echo NULL; fi ),
        "num_simulations" = $( if [ ! -z ${VIASH_PAR_NUM_SIMULATIONS+x} ]; then echo "as.integer($VIASH_PAR_NUM_SIMULATIONS)"; else echo NULL; fi ),
        "census_interval" = $( if [ ! -z ${VIASH_PAR_CENSUS_INTERVAL+x} ]; then echo "as.numeric($VIASH_PAR_CENSUS_INTERVAL)"; else echo NULL; fi ),
        "ssa_tau" = $( if [ ! -z ${VIASH_PAR_SSA_TAU+x} ]; then echo "as.numeric($VIASH_PAR_SSA_TAU)"; else echo NULL; fi ),
        "store_chromatin" = $( if [ ! -z ${VIASH_PAR_STORE_CHROMATIN+x} ]; then echo "as.logical(toupper('$VIASH_PAR_STORE_CHROMATIN'))"; else echo NULL; fi ),
        "store_protein" = $( if [ ! -z ${VIASH_PAR_STORE_PROTEIN+x} ]; then echo "as.logical(toupper('$VIASH_PAR_STORE_PROTEIN'))"; else echo NULL; fi ),
        "num_proteins" = $( if [ ! -z ${VIASH_PAR_NUM_PROTEINS+x} ]; then echo "as.integer($VIASH_PAR_NUM_PROTEINS)"; else echo NULL; fi ),
        "num_threads" = $( if [ ! -z ${VIASH_PAR_NUM_THREADS+x} ]; then echo "as.integer($VIASH_PAR_NUM_THREADS)"; else echo NULL; fi ),
        "seed" = $( if [ ! -z ${VIASH_PAR_SEED+x} ]; then echo "as.integer($VIASH_PAR_SEED)"; else echo NULL; fi ),
        "cache_dir" = $( if [ ! -z ${VIASH_PAR_CACHE_DIR+x} ]; then echo "'$VIASH_PAR_CACHE_DIR'"; else echo NULL; fi )
      )
      
      # get meta parameters
      meta <- list(
        functionality_name = "$VIASH_META_FUNCTIONALITY_NAME",
        resources_dir = "$VIASH_RESOURCES_DIR"
      )
      
      # get resources dir
      resources_dir = "$VIASH_RESOURCES_DIR"
      
      ## VIASH END
      
      if (!is.null(par\$seed)) {
        set.seed(par\$seed)
      }
      if (par\$store_protein == par\$store_chromatin) {
        cat("Warning: Strictly pass one of --store_protein and --store_chromatin, not neither or both.\\n")
      }
      
      # start from given backbone and a cyclic backbone
      backbone_init <- bblego(
        bblego_start("A", type = "simple"),
        bblego_linear("A", "B", num_modules = 10),
        bblego_linear("B", "C", num_modules = 10),
        bblego_linear("C", "D", num_modules = 10),
        bblego_end("D")
      )
      
      
      module_info <- bind_rows(
        backbone_init\$module_info %>% select(-color),
        tribble(
          ~module_id, ~basal, ~burn, ~independence,
          "CC1", 0, TRUE, 1,
          "CC2", 1, TRUE, 1,
          "CC3", 0, TRUE, 1,
          "CC4", 1, TRUE, 1,
          "CC5", 0, TRUE, 1
        )
      )
      
      module_network <- bind_rows(
        backbone_init\$module_network,
        tribble(
          ~from, ~to, ~effect, ~strength, ~hill,
          "Burn1", "CC1", 1L, 1, 2,
          "CC1", "CC2", -1L, 100, 2,
          "CC2", "CC3", 1L, 1, 2,
          "CC3", "CC4", -1L, 100, 2,
          "CC4", "CC5", 1L, 1, 2,
          "CC5", "CC1", -1L, 100, 2
        )
      )
      
      backbone <- backbone(
        module_info = module_info,
        module_network = module_network,
        expression_patterns = backbone_init\$expression_patterns
      )
      
      burn_time <- simtime_from_backbone(backbone, burn = TRUE) * 4
      total_time <- simtime_from_backbone(backbone, burn = FALSE) / 3
      
      cat("Generating regulatory network\\n")
      num_tfs <- nrow(backbone\$module_info)
      num_targets <- ceiling(0.8 * (par\$num_genes - num_tfs))
      num_hks <- par\$num_genes - num_tfs - num_targets
      num_cells_train <- round(par\$num_cells * .66)
      num_cells_test <- par\$num_cells - num_cells_train
      
      model_init <- initialise_model(
        backbone = backbone,
        num_cells = num_cells_train,
        num_tfs = num_tfs,
        num_targets = num_targets,
        num_hks = num_hks,
        simulation_params = simulation_default(
          burn_time = burn_time,
          total_time = total_time,
          census_interval = par\$census_interval,
          ssa_algorithm = ssa_etl(tau = par\$ssa_tau),
          experiment_params = simulation_type_wild_type(
            num_simulations = round(0.66*par\$num_simulations)
          ),
          compute_cellwise_grn = par\$store_chromatin
        ),
        num_cores = par\$num_threads,
        verbose = FALSE,
        download_cache_dir = par\$cache_dir
      ) %>%
        generate_tf_network() %>%
        generate_feature_network()
      
      cat("Running simulations for training cells\\n")
      model_train <-
        model_init %>%
        generate_kinetics() %>%
        generate_gold_standard() %>%
        generate_cells() %>%
        generate_experiment()
      
      cat("Running simulations for test cells\\n")
      model_init\$num_cells <-
        model_init\$numbers\$num_cells <-
        num_cells_test
      model_init\$simulation_params\$experiment_params <-
        simulation_type_wild_type(round(0.37*par\$num_simulations))
      model_test <-
        model_init %>%
        generate_kinetics() %>% # use different kinetics
        generate_gold_standard() %>%
        generate_cells() %>%
        generate_experiment()
      
      cat("Combine simulations into one dataset\\n")
      model <- combine_models(
        list(
          batch1 = model_train,
          batch2 = model_test
        ),
        duplicate_gold_standard = FALSE
      )
      dataset <- as_dyno(model) %>% 
        dynwrap::simplify_trajectory()
      
      milestone_labels <- c("sA" = "start", "sEndD" = "end")
      # check whether output dataset looks nice
      # and whether batch effect is present
      # plot_summary(model)
      
      
      cat("Compute cell cycle scores\\n")
      phase_scores <- map_df(unique(dataset\$cell_info\$model), function(mod) {
        ix <- dataset\$cell_info\$model == mod
        cp <- dataset\$counts_protein[ix, ]
        expr1 <- dynutils::scale_quantile(cp[, "CC2_TF1"])
        expr2 <- dynutils::scale_quantile(cp[, "CC5_TF1"])
        tibble(
          cell_id = rownames(cp),
          S_score = (expr1 - expr2) / 2 + .5,
          G2M_score = (expr2 - expr1) / 2 + .5
        )
      })
      
      # ggplot(phase_scores) + geom_point(aes(S_score, G2M_score))
      cat("Process trajectory percentages")
      trajectory_topology <-
        dataset\$milestone_network %>%
        transmute(
          from = milestone_labels[from],
          to = milestone_labels[to],
          length
        )
      trajectory_percentages <- 
        dataset\$milestone_percentages %>%
        mutate(
          milestone_id = milestone_labels[milestone_id]
        ) %>%
        reshape2::acast(cell_id~milestone_id, value.var = "percentage") %>%
        Matrix::Matrix(sparse = TRUE)
      
      trajectory_percentages <- trajectory_percentages[dataset\$cell_ids, unname(milestone_labels)]
      
      cat("Create RNA dataset\\n")
      celltypes <- dataset\$milestone_percentages %>%
        group_by(cell_id) %>%
        slice(which.max(percentage)) %>%
        ungroup() %>%
        select(cell_id, cell_type = milestone_id)
      obs <- dataset\$cell_info %>%
        left_join(celltypes, by = "cell_id") %>%
        left_join(phase_scores, by = "cell_id") %>%
        rename(batch = model) %>%
        column_to_rownames("cell_id")
      
      # ggplot(obs) + geom_point(aes(pseudotime, G2M_score, colour = batch))
      var <- dataset\$feature_info %>%
        select(feature_id, module_id, basal, burn, independence, color, is_tf, is_hk) %>%
        column_to_rownames("feature_id")
      ad_mod1 <- anndata::AnnData(
        X = dataset\$counts,
        obs = obs,
        var = var %>% mutate(feature_types = "GEX"),
        obsm = list(
          trajectory_percentages = trajectory_percentages
        ),
        uns = list(
          dataset_id = par\$id,
          trajectory_topology = trajectory_topology
        )
      )
      
      if (par\$store_protein) {
        cat("Processing Antibody data\\n")
        # construct AbSeq-like data from protein counts
        # TODO: use real AbSeq data to map distributions
        counts_protein <- dataset\$counts_protein
        var_protein <- var %>% mutate(feature_types = "ADT")
      
        # sample 50 genes
        if (ncol(counts_protein) > par\$num_proteins) {
          sample_genes <- sample.int(ncol(counts_protein), par\$num_proteins)
          counts_protein <- counts_protein[,sample_genes, , drop = FALSE]
          var_protein <- var_protein[sample_genes, , drop = FALSE]
        }
      
        ad_mod2 <- anndata::AnnData(
          X = counts_protein,
          obs = obs,
          var = var_protein,
          obsm = list(
            trajectory_percentages = trajectory_percentages
          ),
          uns = list(
            dataset_id = par\$id,
            trajectory_topology = trajectory_topology
          )
        )
      }
      
      if (par\$store_chromatin) {
        cat("Processing ATAC data\\n")
        # constuct atac-like data from single cell regulatory network
        # TODO: use real atac data to map distributions
        mat <- dataset\$regulatory_network_sc %>%
          mutate(
            edge = factor(paste0(as.character(regulator), "->", as.character(target)))
          )
        regsc <- Matrix::sparseMatrix(
          i = as.integer(mat\$cell_id),
          j = as.integer(mat\$edge),
          x = pmax(mat\$strength, 0)*100
        )
        rownames(regsc) <- dataset\$cell_ids
        colnames(regsc) <- paste0("region_", seq_len(ncol(regsc)))
        var_atac <- data.frame(
          row.names = colnames(regsc),
          feature_types = rep("ATAC", ncol(regsc))
        )
      
        ad_mod2 <- anndata::AnnData(
          X = regsc,
          obs = obs,
          var = var_atac,
          obsm = list(
            trajectory_percentages = trajectory_percentages
          ),
          uns = list(
            dataset_id = par\$id,
            organism = "synthetic"
          )
        )
      }
      
      cat("Write h5ad files\\n")
      ad_mod1\$write_h5ad(par\$output_rna, compression = "gzip")
      ad_mod2\$write_h5ad(par\$output_mod2, compression = "gzip")
      
      if (!is.null(par\$plot)) {
        cat("Storing summary plot\\n")
        g <- plot_summary(model)
        ggsave(par\$plot, g, width = 20, height = 16)
      }
      VIASHMAIN
      PATH="$VIASH_RESOURCES_DIR:\$PATH"
      
      Rscript "\$tempscript"
      
      VIASHEOF
      

    dest: "simulate_dyngen_dataset"
    is_executable: true
  - type: "file"
    text: |
        docker.enabled = true
        docker.runOptions = "-i -v ${baseDir}:${baseDir}"
        process.container = "dataintuitive/viash"
        params {
          simulate_dyngen_dataset__id = "viash_no_value"
          simulate_dyngen_dataset__output_rna = "viash_no_value"
          simulate_dyngen_dataset__output_mod2 = "viash_no_value"
          simulate_dyngen_dataset__plot = "viash_no_value"
          simulate_dyngen_dataset__num_cells = "100"
          simulate_dyngen_dataset__num_genes = "100"
          simulate_dyngen_dataset__num_simulations = "32"
          simulate_dyngen_dataset__census_interval = "4.0"
          simulate_dyngen_dataset__ssa_tau = "0.008333"
          simulate_dyngen_dataset__store_chromatin = "no_default_value_configured"
          simulate_dyngen_dataset__store_protein = "no_default_value_configured"
          simulate_dyngen_dataset__num_proteins = "50"
          simulate_dyngen_dataset__num_threads = "1"
          simulate_dyngen_dataset__seed = "no_default_value_configured"
          simulate_dyngen_dataset__cache_dir = "no_default_value_configured"
          id = ""
          testScript = "test.R"
          testResources = [ "test.R" ]
          simulate_dyngen_dataset {
            name = "simulate_dyngen_dataset"
            container = "common_datasets_simulate_dyngen_dataset"
            containerTag = "main_build"
            containerRegistry = "openproblems"
            command = "simulate_dyngen_dataset"
            tests {
              isDefined = true
              testScript = "test.R"
              testResources = [ "test.R" ]
            }
            arguments {
              id {
                name = "id"
                otype = "--"
                required = true
                type = "string"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__id}"
                example = "dyngen_dataset"
                description = "The id of the output dataset id"
              }
              output_rna {
                name = "output_rna"
                otype = "--"
                required = true
                type = "file"
                direction = "Output"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__output_rna}"
                example = "output_rna.h5ad"
                description = "Output h5ad RNA file."
              }
              output_mod2 {
                name = "output_mod2"
                otype = "--"
                required = true
                type = "file"
                direction = "Output"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__output_mod2}"
                example = "output_mod2.h5ad"
                description = "Output h5ad modality2 file (ATAC or Antibody capture)."
              }
              plot {
                name = "plot"
                otype = "--"
                required = true
                type = "file"
                direction = "Output"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__plot}"
                example = "plot.pdf"
                description = "A visualisation of the simulation."
              }
              num_cells {
                name = "num_cells"
                otype = "--"
                required = false
                type = "integer"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__num_cells}"
                dflt = "100"
                description = "The number of cells to generate."
              }
              num_genes {
                name = "num_genes"
                otype = "--"
                required = false
                type = "integer"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__num_genes}"
                dflt = "100"
                description = "The number of genes to generate."
              }
              num_simulations {
                name = "num_simulations"
                otype = "--"
                required = false
                type = "integer"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__num_simulations}"
                dflt = "32"
                description = "The number of dyngen simulations to run."
              }
              census_interval {
                name = "census_interval"
                otype = "--"
                required = false
                type = "double"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__census_interval}"
                dflt = "4.0"
                description = "A granularity parameter for the outputted simulation."
              }
              ssa_tau {
                name = "ssa_tau"
                otype = "--"
                required = false
                type = "double"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__ssa_tau}"
                dflt = "0.008333"
                description = "Step size of the GillespieSSA2 simulation. Default is 30/3600."
              }
              store_chromatin {
                name = "store_chromatin"
                otype = "--"
                required = false
                type = "boolean_true"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__store_chromatin}"
                description = "Whether or not to compute chromatin accessibility data."
              }
              store_protein {
                name = "store_protein"
                otype = "--"
                required = false
                type = "boolean_true"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__store_protein}"
                description = "Whether or not to store protein count information."
              }
              num_proteins {
                name = "num_proteins"
                otype = "--"
                required = false
                type = "integer"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__num_proteins}"
                dflt = "50"
                description = "The number of proteins to sample."
              }
              num_threads {
                name = "num_threads"
                otype = "--"
                required = false
                type = "integer"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__num_threads}"
                dflt = "1"
                description = "Parallellisation level."
              }
              seed {
                name = "seed"
                otype = "--"
                required = false
                type = "integer"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__seed}"
                description = "Seed"
              }
              cache_dir {
                name = "cache_dir"
                otype = "--"
                required = false
                type = "file"
                direction = "Input"
                multiple = false
                multiple_sep = ":"
                value = "${params.simulate_dyngen_dataset__cache_dir}"
                description = "A caching directory for files that dyngen downloads."
              }
            }
          }
        }

    dest: "nextflow.config"
  - type: "file"
    text: |
      nextflow.enable.dsl=2
      
      params.test = false
      params.debug = false
      params.publishDir = "./"
      
      // A function to verify (at runtime) if all required arguments are effectively provided.
      def checkParams(_params) {
        _params.arguments.collect{
          if (it.value == "viash_no_value") {
            println("[ERROR] option --${it.name} not specified in component simulate_dyngen_dataset")
            println("exiting now...")
              exit 1
          }
        }
      }
      
      
      def escape(str) {
        return str.replaceAll('\\\\', '\\\\\\\\').replaceAll("\"", "\\\\\"").replaceAll("\n", "\\\\n").replaceAll("`", "\\\\`")
      }
      
      def renderArg(it) {
        if (it.otype == "") {
          return "'" + escape(it.value) + "'"
        } else if (it.type == "boolean_true") {
          if (it.value.toLowerCase() == "true") {
            return it.otype + it.name
          } else {
            return ""
          }
        } else if (it.type == "boolean_false") {
          if (it.value.toLowerCase() == "true") {
            return ""
          } else {
            return it.otype + it.name
          }
        } else if (it.value == "no_default_value_configured") {
          return ""
        } else {
          def retVal = it.value in List && it.multiple ? it.value.join(it.multiple_sep): it.value
          return it.otype + it.name + " '" + escape(retVal) + "'"
        }
      }
      
      def renderCLI(command, arguments) {
        def argumentsList = arguments.collect{renderArg(it)}.findAll{it != ""}
      
        def command_line = command + argumentsList
      
        return command_line.join(" ")
      }
      
      def effectiveContainer(processParams) {
        def _registry = params.containsKey("containerRegistry") ? params.containerRegistry : processParams.containerRegistry
        def _name = processParams.container
        def _tag = params.containsKey("containerTag") ? params.containerTag : processParams.containerTag
      
        return (_registry == "" ? "" : _registry + "/") + _name + ":" + _tag
      }
      
      // Convert the nextflow.config arguments list to a List instead of a LinkedHashMap
      // The rest of this main.nf script uses the Map form
      def argumentsAsList(_params) {
        def overrideArgs = _params.arguments.collect{ key, value -> value }
        def newParams = _params + [ "arguments" : overrideArgs ]
        return newParams
      }
      
      
      // Use the params map, create a hashmap of the filenames for output
      // output filename is <sample>.<method>.<arg_name>[.extension]
      def outFromIn(_params) {
      
        def id = _params.id
      
        _params
          .arguments
          .findAll{ it -> it.type == "file" && it.direction == "Output" }
          .collect{ it ->
            // If an 'example' attribute is present, strip the extension from the filename,
            // If a 'dflt' attribute is present, strip the extension from the filename,
            // Otherwise just use the option name as an extension.
            def extOrName =
              (it.example != null)
                ? it.example.split(/\./).last()
                : (it.dflt != null)
                  ? it.dflt.split(/\./).last()
                  : it.name
            // The output filename is <sample> . <modulename> . <extension>
            // Unless the output argument is explicitly specified on the CLI
            def newValue =
              (it.value == "viash_no_value")
                ? "simulate_dyngen_dataset." + it.name + "." + extOrName
                : it.value
            def newName =
              (id != "")
                ? id + "." + newValue
                : it.name + newValue
            it + [ value : newName ]
          }
      
      }
      
      // A process that filters out output_rna from the output Map
      process filterOutput_rna {
      
        input:
          tuple val(id), val(input), val(_params)
        output:
          tuple val(id), val(output), val(_params)
        when:
          input.keySet().contains("output_rna")
        exec:
          output = input["output_rna"]
      
      }
      
      // A process that filters out output_mod2 from the output Map
      process filterOutput_mod2 {
      
        input:
          tuple val(id), val(input), val(_params)
        output:
          tuple val(id), val(output), val(_params)
        when:
          input.keySet().contains("output_mod2")
        exec:
          output = input["output_mod2"]
      
      }
      
      // A process that filters out plot from the output Map
      process filterPlot {
      
        input:
          tuple val(id), val(input), val(_params)
        output:
          tuple val(id), val(output), val(_params)
        when:
          input.keySet().contains("plot")
        exec:
          output = input["plot"]
      
      }
      
      def overrideIO(_params, inputs, outputs) {
      
        // `inputs` in fact can be one of:
        // - `String`,
        // - `List[String]`,
        // - `Map[String, String | List[String]]`
        // Please refer to the docs for more info
        def overrideArgs = _params.arguments.collect{ it ->
          if (it.type == "file") {
            if (it.direction == "Input") {
              (inputs in List || inputs in HashMap)
                ? (inputs in List)
                  ? it + [ "value" : inputs.join(it.multiple_sep)]
                  : (inputs[it.name] != null)
                    ? (inputs[it.name] in List)
                      ? it + [ "value" : inputs[it.name].join(it.multiple_sep)]
                      : it + [ "value" : inputs[it.name]]
                    : it
                : it + [ "value" : inputs ]
            } else {
              (outputs in List || outputs in HashMap)
                ? (outputs in List)
                  ? it + [ "value" : outputs.join(it.multiple_sep)]
                  : (outputs[it.name] != null)
                    ? (outputs[it.name] in List)
                      ? it + [ "value" : outputs[it.name].join(it.multiple_sep)]
                      : it + [ "value" : outputs[it.name]]
                    : it
                : it + [ "value" : outputs ]
            }
          } else {
            it
          }
        }
      
        def newParams = _params + [ "arguments" : overrideArgs ]
      
        return newParams
      
      }
      
      process simulate_dyngen_dataset_process {
        cpus 8
        tag "${id}"
        echo { (params.debug == true) ? true : false }
        cache 'deep'
        stageInMode "symlink"
        container "${container}"
      
        input:
          tuple val(id), path(input), val(output), val(container), val(cli), val(_params)
        output:
          tuple val("${id}"), path(output), val(_params)
        stub:
          """
          # Adding NXF's `$moduleDir` to the path in order to resolve our own wrappers
          export PATH="${moduleDir}:\$PATH"
          STUB=1 $cli
          """
        script:
          def viash_temp = System.getenv("VIASH_TEMP") ?: "/tmp/"
          if (params.test)
            """
            # Some useful stuff
            export NUMBA_CACHE_DIR=/tmp/numba-cache
            # Running the pre-hook when necessary
            # Pass viash temp dir
            export VIASH_TEMP="${viash_temp}"
            # Adding NXF's `$moduleDir` to the path in order to resolve our own wrappers
            export PATH="./:${moduleDir}:\$PATH"
            ./${params.simulate_dyngen_dataset.tests.testScript} | tee $output
            """
          else
            """
            # Some useful stuff
            export NUMBA_CACHE_DIR=/tmp/numba-cache
            # Running the pre-hook when necessary
            # Pass viash temp dir
            export VIASH_TEMP="${viash_temp}"
            # Adding NXF's `$moduleDir` to the path in order to resolve our own wrappers
            export PATH="${moduleDir}:\$PATH"
            $cli
            """
      }
      
      workflow simulate_dyngen_dataset {
      
        take:
        id_input_params_
      
        main:
      
        def key = "simulate_dyngen_dataset"
      
        def id_input_output_function_cli_params_ =
          id_input_params_.map{ id, input, _params ->
      
            // Start from the (global) params and overwrite with the (local) _params
            def defaultParams = params[key] ? params[key] : [:]
            def overrideParams = _params[key] ? _params[key] : [:]
            def updtParams = defaultParams + overrideParams
            // Convert to List[Map] for the arguments
            def newParams = argumentsAsList(updtParams) + [ "id" : id ]
      
            // Generate output filenames, out comes a Map
            def output = outFromIn(newParams)
      
            // The process expects Path or List[Path], Maps need to be converted
            def inputsForProcess =
              (input in HashMap)
                ? input.collect{ k, v -> v }.flatten()
                : input
            def outputsForProcess = output.collect{ it.value }
      
            // For our machinery, we convert Path -> String in the input
            def inputs =
              (input in List || input in HashMap)
                ? (input in List)
                  ? input.collect{ it.name }
                  : input.collectEntries{ k, v -> [ k, (v in List) ? v.collect{it.name} : v.name ] }
                : input.name
            outputs = output.collectEntries{ [(it.name): it.value] }
      
            def finalParams = overrideIO(newParams, inputs, outputs)
      
            checkParams(finalParams)
      
            new Tuple6(
              id,
              inputsForProcess,
              outputsForProcess,
              effectiveContainer(finalParams),
              renderCLI([finalParams.command], finalParams.arguments),
              finalParams
            )
          }
      
        result_ = simulate_dyngen_dataset_process(id_input_output_function_cli_params_)
          | join(id_input_params_)
          | map{ id, output, _params, input, original_params ->
              def parsedOutput = _params.arguments
                .findAll{ it.type == "file" && it.direction == "Output" }
                .withIndex()
                .collectEntries{ it, i ->
                  // with one entry, output is of type Path and array selections
                  // would select just one element from the path
                  [(it.name): (output in List) ? output[i] : output ]
                }
              new Tuple3(id, parsedOutput, original_params)
            }
      
        result_
           | filter { it[1].keySet().size() > 1 }
           | view{">> Be careful, multiple outputs from this component!"}
      
        emit:
        result_.flatMap{ it ->
          (it[1].keySet().size() > 1)
            ? it[1].collect{ k, el -> [ it[0], [ (k): el ], it[2] ] }
            : it[1].collect{ k, el -> [ it[0], el, it[2] ] }
        }
      }
      
      workflow {
        def id = params.id
        def fname = "simulate_dyngen_dataset"
      
        def _params = params
      
        // could be refactored to be FP
        for (entry in params[fname].arguments) {
          def name = entry.value.name
          if (params[name] != null) {
            params[fname].arguments[name].value = params[name]
          }
        }
      
        def inputFiles = params.simulate_dyngen_dataset
          .arguments
          .findAll{ key, par -> par.type == "file" && par.direction == "Input" }
          .collectEntries{ key, par -> [(par.name): file(params[fname].arguments[par.name].value) ] }
      
        def ch_ = Channel.from("").map{ s -> new Tuple3(id, inputFiles, params)}
      
        result = simulate_dyngen_dataset(ch_)
      
        result \
          | filterOutput_rna \
          | view{ "Output for output_rna: " + it[1] }
      
      
        result \
          | filterOutput_mod2 \
          | view{ "Output for output_mod2: " + it[1] }
      
      
        result \
          | filterPlot \
          | view{ "Output for plot: " + it[1] }
      
      }
      
      // This workflow is not production-ready yet, we leave it in for future dev
      // TODO
      workflow test {
      
        take:
        rootDir
      
        main:
        params.test = true
        params.simulate_dyngen_dataset.output = "simulate_dyngen_dataset.log"
      
        Channel.from(rootDir) \
          | filter { params.simulate_dyngen_dataset.tests.isDefined } \
          | map{ p -> new Tuple3(
              "tests",
              params.simulate_dyngen_dataset.tests.testResources.collect{ file( p + it ) },
              params
          )} \
          | simulate_dyngen_dataset
      
        emit:
        simulate_dyngen_dataset.out
      }

    dest: "main.nf"
  description: "Generate a synthetic dataset using the standard dyngen simulation\
    \ workflow.\nFor more advanced usage to get more control over the outputted dataset,\
    \ use the\nR package. More documentation can be found at https://dyngen.dynverse.org.\n"
  tests:
  - type: "r_script"
    path: "test.R"
    is_executable: true
  info:
    doi: "10.1038/s41467-021-24152-2"
    url: "https://dyngen.dynverse.org"
platform:
  type: "nextflow"
  id: "nextflow"
  registry: "openproblems"
  namespace_separator: "_"
  separate_multiple_outputs: true
  labels: []
  directive_cpus: 8
platforms: []
info:
  config: "src/common/datasets/simulate_dyngen_dataset/config.vsh.yaml"
  platform: "nextflow"
  output: "target/nextflow/common_datasets/simulate_dyngen_dataset"
  executable: "target/nextflow/common_datasets/simulate_dyngen_dataset/simulate_dyngen_dataset"
  viash_version: "0.5.3dev"
  git_commit: "16a07758c7f08359659b55464622e34b20bccdc2"
  git_remote: "https://github.com/openproblems-bio/neurips2021_multimodal_viash"
