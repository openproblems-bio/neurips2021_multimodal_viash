  docker.enabled = true
  docker.runOptions = "-i -v ${baseDir}:${baseDir}"
  process.container = "dataintuitive/viash"
  params {
    aupr__input_prediction = "no_default_value_configured"
    aupr__input_solution = "viash_no_value"
    aupr__output = "viash_no_value"
    id = ""
    testScript = "test_metric.py"
    testResources = [ "../../unit_tests/test_metric.py", "test_custom.R", "../../../../resources_test", "metric_meta_aupr.tsv" ]
    aupr {
      name = "aupr"
      container = "match_modality_metrics_aupr"
      containerTag = "1.1.0"
      containerRegistry = "openproblems"
      command = "aupr"
      tests {
        isDefined = true
        testScript = "test_metric.py"
        testResources = [ "../../unit_tests/test_metric.py", "test_custom.R", "../../../../resources_test", "metric_meta_aupr.tsv" ]
      }
      arguments {
        input_prediction {
          name = "input_prediction"
          otype = "--"
          required = false
          type = "file"
          direction = "Input"
          multiple = false
          multiple_sep = ":"
          value = "${params.aupr__input_prediction}"
          example = "prediction.h5ad"
          description = "Prediction by a method."
        }
        input_solution {
          name = "input_solution"
          otype = "--"
          required = true
          type = "file"
          direction = "Input"
          multiple = false
          multiple_sep = ":"
          value = "${params.aupr__input_solution}"
          example = "solution.h5ad"
          description = "Gold standard solution."
        }
        output {
          name = "output"
          otype = "--"
          required = true
          type = "file"
          direction = "Output"
          multiple = false
          multiple_sep = ":"
          value = "${params.aupr__output}"
          example = "output.h5ad"
          description = "Metric scores by comparing the prediction to the gold standard solution."
        }
      }
    }
  }